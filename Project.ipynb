{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bad795b-cddb-469a-a2ad-99e14dafa7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a83b6a8-82be-4745-a401-f103d767c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Gemini API - replace with your actual API key\n",
    "api_key = \"AIzaSyB5fCVl9XTUQfV8qSqJG04MbG2EOGYsXiU\"  # Get your key from: https://aistudio.google.com/app/apikey\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash-latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37b6793d-6c83-4da4-8318-1afc7a32b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    \"\"\"Process image for Gemini API\"\"\"\n",
    "    # Convert Gradio image (numpy array) to bytes\n",
    "    _, buffer = cv2.imencode('.jpg', image)\n",
    "    image_bytes = buffer.tobytes()\n",
    "    \n",
    "    # Convert to base64\n",
    "    return base64.b64encode(image_bytes).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a383676-dcfa-4c59-b991-d1db977d9810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_asl(image):\n",
    "    \"\"\"Recognize ASL letter from image using Gemini\"\"\"\n",
    "    if image is None:\n",
    "        return \"Please capture an image first\", None\n",
    "    \n",
    "    try:\n",
    "        # Prepare image and prompt\n",
    "        base64_image = process_image(image)\n",
    "        prompt = \"\"\"\n",
    "        Identify the American Sign Language (ASL) letter shown in this image. \n",
    "        Only respond with the single letter (A, B, C, D, or E) if recognized. \n",
    "        If unclear, respond 'Unknown'. \n",
    "        Do not include any other text or explanation.\n",
    "                \n",
    "        Image:\n",
    "        \"\"\"\n",
    "        \n",
    "        # Call Gemini API\n",
    "        response = model.generate_content(\n",
    "            [prompt, {\"mime_type\": \"image/jpeg\", \"data\": base64_image}],\n",
    "            stream=False\n",
    "        )\n",
    "        \n",
    "        # Process response\n",
    "        result = response.text.strip().upper()\n",
    "        valid_letters = ['A', 'B', 'C', 'D', 'E']\n",
    "        \n",
    "        # Create result image with annotation\n",
    "        img_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        draw = ImageDraw.Draw(img_pil)\n",
    "        \n",
    "        try:\n",
    "            # Try to load a font (works on most systems)\n",
    "            font = ImageFont.truetype(\"arial.ttf\", 60)\n",
    "        except:\n",
    "            # Fallback to default font\n",
    "            font = ImageFont.load_default()\n",
    "        \n",
    "        text = f\"Result: {result}\" if result in valid_letters else \"Unknown\"\n",
    "        text_color = (0, 128, 0) if result in valid_letters else (200, 0, 0)\n",
    "        \n",
    "        # Calculate text size and position\n",
    "        text_bbox = draw.textbbox((0, 0), text, font=font)\n",
    "        text_width = text_bbox[2] - text_bbox[0]\n",
    "        text_height = text_bbox[3] - text_bbox[1]\n",
    "        position = ((img_pil.width - text_width) // 2, 20)\n",
    "        \n",
    "        # Draw background and text\n",
    "        draw.rectangle([position[0]-10, position[1]-10, \n",
    "                       position[0]+text_width+10, position[1]+text_height+10], \n",
    "                      fill=(255, 255, 255, 180))\n",
    "        draw.text(position, text, fill=text_color, font=font)\n",
    "        \n",
    "        # Convert back to numpy array for Gradio\n",
    "        result_img = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        return result, result_img\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"API Error: {str(e)}\"\n",
    "        return error_msg, None\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e99873-c99c-4b23-8e2c-f5413c81636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_example_image(letter):\n",
    "    \"\"\"Generate an example image for ASL letters\"\"\"\n",
    "    img_size = 300\n",
    "    img = Image.new('RGB', (img_size, img_size), color=(240, 240, 240))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 120)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    # Draw letter in center\n",
    "    text = letter\n",
    "    text_bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    text_width = text_bbox[2] - text_bbox[0]\n",
    "    text_height = text_bbox[3] - text_bbox[1]\n",
    "    position = ((img_size - text_width) // 2, (img_size - text_height) // 2)\n",
    "    \n",
    "    draw.text(position, text, fill=(0, 0, 0), font=font)\n",
    "    \n",
    "    # Draw hand outline\n",
    "    draw.ellipse((50, 50, 250, 250), outline=(150, 150, 150), width=3)\n",
    "    \n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50520b7a-2ad1-48f0-8cee-ffc10d6a8e8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Cannot call click outside of a gradio.Blocks context.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 43\u001b[0m\n\u001b[0;32m     34\u001b[0m         example_images\u001b[38;5;241m.\u001b[39mappend(generate_example_image(letter))\n\u001b[0;32m     36\u001b[0m     examples \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mExamples(\n\u001b[0;32m     37\u001b[0m         examples\u001b[38;5;241m=\u001b[39mexample_images,\n\u001b[0;32m     38\u001b[0m         inputs\u001b[38;5;241m=\u001b[39mimage_input,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m         examples_per_page\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     42\u001b[0m     )\n\u001b[1;32m---> 43\u001b[0m btn\u001b[38;5;241m.\u001b[39mclick(recognize_asl, inputs\u001b[38;5;241m=\u001b[39mimage_input, outputs\u001b[38;5;241m=\u001b[39m[output_text, output_image])\n\u001b[0;32m     44\u001b[0m image_input\u001b[38;5;241m.\u001b[39mchange(recognize_asl, inputs\u001b[38;5;241m=\u001b[39mimage_input, outputs\u001b[38;5;241m=\u001b[39m[output_text, output_image])\n\u001b[0;32m     45\u001b[0m app\u001b[38;5;241m.\u001b[39mlaunch(debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gradio\\events.py:665\u001b[0m, in \u001b[0;36mEventListener._setup.<locals>.event_trigger\u001b[1;34m(block, fn, inputs, outputs, api_name, scroll_to_output, show_progress, show_progress_on, queue, batch, max_batch_size, preprocess, postprocess, cancels, trigger_mode, js, concurrency_limit, concurrency_id, show_api, time_limit, stream_every, like_user_message, key)\u001b[0m\n\u001b[0;32m    663\u001b[0m root_block \u001b[38;5;241m=\u001b[39m get_blocks_context()\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m root_block \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 665\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    666\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_event_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m outside of a gradio.Blocks context.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    667\u001b[0m     )\n\u001b[0;32m    669\u001b[0m event_target \u001b[38;5;241m=\u001b[39m EventListenerMethod(\n\u001b[0;32m    670\u001b[0m     block \u001b[38;5;28;01mif\u001b[39;00m _has_trigger \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, _event_name\n\u001b[0;32m    671\u001b[0m )\n\u001b[0;32m    673\u001b[0m dep, dep_index \u001b[38;5;241m=\u001b[39m root_block\u001b[38;5;241m.\u001b[39mset_event_trigger(\n\u001b[0;32m    674\u001b[0m     [event_target],\n\u001b[0;32m    675\u001b[0m     fn,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    705\u001b[0m     key\u001b[38;5;241m=\u001b[39mkey,\n\u001b[0;32m    706\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: Cannot call click outside of a gradio.Blocks context."
     ]
    }
   ],
   "source": [
    "# Create Gradio interface\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as app:\n",
    "    gr.Markdown(\"# üñêÔ∏è ASL Letter Recognition\")\n",
    "    gr.Markdown(\"Show ASL signs for letters **A, B, C, D, or E** using your webcam or upload an image\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            image_input = gr.Image(sources=[\"webcam\", \"upload\"], \n",
    "                                  label=\"Capture ASL Sign\",\n",
    "                                  height=300)\n",
    "            btn = gr.Button(\"Recognize Letter\", variant=\"primary\")\n",
    "            \n",
    "        with gr.Column(scale=1):\n",
    "            output_text = gr.Textbox(label=\"Recognized Letter\", \n",
    "                                   placeholder=\"Letter will appear here\")\n",
    "            output_image = gr.Image(label=\"Annotated Result\", height=300)\n",
    "    \n",
    "    with gr.Accordion(\"Tips for better recognition\", open=False):\n",
    "        gr.Markdown(\"\"\"\n",
    "        - Make sure your hand is clearly visible against a contrasting background\n",
    "        - Position your hand in the center of the frame\n",
    "        - Use these standard ASL signs:\n",
    "            - **A**: Fist with thumb alongside\n",
    "            - **B**: Flat hand, fingers together\n",
    "            - **C**: Curved hand like a 'C' shape\n",
    "            - **D**: Index finger pointing up, other fingers in fist\n",
    "            - **E**: Fist with thumb across fingers\n",
    "                    - Avoid shadows on your hand\n",
    "        \"\"\")\n",
    "    \n",
    "    # Generate example images if local files are missing\n",
    "    example_images = []\n",
    "    for letter in ['A', 'B', 'C', 'D', 'E']:\n",
    "        example_images.append(generate_example_image(letter))\n",
    "    \n",
    "    examples = gr.Examples(\n",
    "        examples=example_images,\n",
    "        inputs=image_input,\n",
    "        outputs=[output_text, output_image],\n",
    "        label=\"Example Images\",\n",
    "        examples_per_page=5\n",
    "    )\n",
    "btn.click(recognize_asl, inputs=image_input, outputs=[output_text, output_image])\n",
    "image_input.change(recognize_asl, inputs=image_input, outputs=[output_text, output_image])\n",
    "app.launch(debug=True)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e633962-c655-472f-9f3e-f4966cc33228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebc77ea-189f-420d-ab90-0109f11da6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
